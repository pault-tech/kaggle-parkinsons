{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Protein BERT Starter Notebook - LB 0.30\nThis notebook demonstrates how to finetune an NLP transformer to compete in Kaggle's Novozymes Enzyme Stability Prediction competition. We train with Jin's external data described [here][2] which uses delta `Tm` and delta `dG` targets. How to train with `dTm` target instead of `Tm` target is explained [here][4]. We use the PyTorch pipeline from Y.Nakama's starter NLP notebook from Feedback Prize 3 competition [here][1]. We will finetune HuggingFace's pretrained `Rostlab/prot_bert` model.\n\nThe competition FP3 is a regression NLP task. Our competition NESP is also a regression task and we can treat protein amino acid sequences as \"sentences\" where each amino acid is a \"word\". \n\nThe secret ingredient for success is the architecture of our model. In FP3 we feed one sentence and get one regression. In NESP, we must feed two \"sentences\". We input both the wild type sequence and mutant sequence into our model. Then we subtract the embeddings and concatenate that result with the wild type and mutant embeddings. We do this both with the specific mutant amino acid token output embedding, and the entire sequences embedding after mean pooling. Finally we use a dense layer to predict one regression target. See diagram below and review code in code cell 23.\n\n![](https://raw.githubusercontent.com/cdeotte/Kaggle_Images/main/Oct-2022/prot_bert.png)\n\nFurthermore, we freeze 22 out of the 30 blocks of Protein BERT to retain most of Protein BERT original pretraining knowledge which improves CV LB. By modifying the architecture, freezing, training schedule, and other hyperparameters, it is possible to improve this notebook's CV LB. Also we can use different train data like FireProtDB [here][6]. Or we can use Vladimir's large mutation dataset [here][9]. Also we can try using different pretrained transformers besides `Rostlab/prot_bert` like Facebooks's ESM or MSA [here][5]. This notebook trains 3 out of 5 folds. Using more folds improves CV LB. Note version 4+ use ESM2 transformer.\n\nCurrently we are using Kaggle's new 1xT4 GPU instead of 1xP100 GPU. This gives us 1.6x speed up. This is because T4 GPU can utilize mixed precision better than P100 GPU. **UPDATE:** CPMP got 2xT4 to work! He published a notebook [here][7]. This gives approximately another 2x speed up (for total of 3x speed up wow!) if we increase batch size too. \n\nNote my version 4 had a variable error (code worked correctly) (it was regarding freezing and unfreezing ESM2 layers/blocks) which is also in CPMP's version 1 and 2. My version 5 corrects this. See version notes below and see discussion update [here][8]. The processed training data for this notebook comes from my XGB notebook [here][3] version 17. (In code cell 9, we save the dataframe after `df = pd.concat([df,df2,df3,kaggle])` before removing any rows).\n\n## Notes:\n\n* **Version 1-3** finetunes HuggingFace's `Rostlab/prot_bert` 3 out of 5 folds and achieves single model LB 0.153. If we train with `batch_size=16` and `LR=1e-5` then single fold 0 achieves LB 0.209 (confirmed with offline training). However in Kaggle notebook, i cannot train with that large batch size and `gradient_checkpointing` nor `gradient_accumulation_steps` replicates large batch results. Not sure why. \n* **Version 4** finetunes HuggingFace's `facebook/esm2_t33_650M_UR50D` 5 out of 5 folds and achieves single model LB 0.292. We freeze 30 out of 33 blocks (of layers) and finetune the last 3 blocks for 1 epoch. We use 1xT4 GPU vs. 1xP100 GPU for 1.6x speedup!\n* **Version 5** Version 5 freezes the same layers/blocks as version 4 except we correct the code variables to accurately say what is happening. In both version 4 and 5 we are actually freezing 30 of the 33 ESM2 blocks and leaving 3 blocks unfrozen. Each block contains 16 layers and there are 2 initial layers before all the blocks. For more info see update to discussion [here][8].\n* **Version 6** stay tuned for more versions...\n\n[1]: https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-train\n[2]: https://www.kaggle.com/competitions/novozymes-enzyme-stability-prediction/discussion/356182\n[3]: https://www.kaggle.com/code/cdeotte/xgboost-5000-mutations-200-pdb-files-lb-0-40\n[4]: https://www.kaggle.com/competitions/novozymes-enzyme-stability-prediction/discussion/358320\n[5]: https://github.com/facebookresearch/esm\n[6]: https://www.kaggle.com/code/dschettler8845/novo-esp-fireprotdb-a-better-train-dataset\n[7]: https://www.kaggle.com/code/cpmpml/protein-bert-finetune-with-2-t4\n[8]: https://www.kaggle.com/competitions/novozymes-enzyme-stability-prediction/discussion/361674\n[9]: https://www.kaggle.com/code/vslaykovsky/9929-unique-mutations-voxel-features-pdbs","metadata":{"papermill":{"duration":0.006995,"end_time":"2022-08-31T22:31:20.199821","exception":false,"start_time":"2022-08-31T22:31:20.192826","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Directory settings","metadata":{"papermill":{"duration":0.006899,"end_time":"2022-08-31T22:31:20.215491","exception":false,"start_time":"2022-08-31T22:31:20.208592","status":"completed"},"tags":[]}},{"cell_type":"code","source":"VER = 5","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:12:59.912979Z","iopub.execute_input":"2022-10-28T20:12:59.913383Z","iopub.status.idle":"2022-10-28T20:12:59.94289Z","shell.execute_reply.started":"2022-10-28T20:12:59.913304Z","shell.execute_reply":"2022-10-28T20:12:59.941999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = f'VER_{VER}/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"papermill":{"duration":0.027843,"end_time":"2022-08-31T22:31:20.251266","exception":false,"start_time":"2022-08-31T22:31:20.223423","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-10-28T20:12:59.945386Z","iopub.execute_input":"2022-10-28T20:12:59.945772Z","iopub.status.idle":"2022-10-28T20:12:59.950869Z","shell.execute_reply.started":"2022-10-28T20:12:59.945736Z","shell.execute_reply":"2022-10-28T20:12:59.94986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CFG","metadata":{"papermill":{"duration":0.00523,"end_time":"2022-08-31T22:31:20.262025","exception":false,"start_time":"2022-08-31T22:31:20.256795","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    wandb=False\n    competition='FB3'\n    _wandb_kernel='nakama'\n    debug=False\n    apex=True\n    print_freq=20\n    num_workers=0\n    # Suggest: Rostlab/prot_bert or ESMs at https://huggingface.co/models?sort=downloads&search=esm\n    # ESM examples: facebook/esm2_t33_650M_UR50D, facebook/esm1v_t33_650M_UR90S_1, facebook/esm1b_t33_650M_UR50S, etc \n    model=\"facebook/esm2_t33_650M_UR50D\" \n    gradient_checkpointing=False\n    scheduler='constant' # ['linear', 'cosine', 'constant']\n    batch_scheduler=True\n    num_warmup_steps=0\n    \n    # LEARNING RATE\n    # Suggested for batchsize=8: Prot_bert = 5e-6, ESM2 = 5e-5\n    epochs=1\n    num_cycles=1.0 #only affects cosine schedule\n    encoder_lr=5e-5\n    decoder_lr=5e-5\n    batch_size=8\n    \n    # MODEL INFO - PROT_BERT\n    total_blocks = 30 \n    initial_layers = 5 \n    layers_per_block = 16 \n    # MODEL INFO - FACEBOOK ESM2\n    if 'esm2' in model:\n        total_blocks = int(model.split('_')[1][1:])\n        initial_layers = 2 \n        layers_per_block = 16 \n        print('esm2 detected')\n    # MODEL INFO - FACEBOOK ESM1B\n    elif 'esm1b' in model:\n        total_blocks = int(model.split('_')[1][1:])\n        initial_layers = 4 \n        layers_per_block = 16 \n        print('esm1b detected')\n    # MODEL INFO - FACEBOOK ESM1V\n    elif 'esm1v' in model:\n        total_blocks = int(model.split('_')[1][1:])\n        initial_layers = 2 \n        layers_per_block = 16 \n        print('esm1v detected')\n    else:\n        print('prot_bert detected')\n        \n    # FREEZE\n    # Suggested: Prot_bert -8, ESM2 -3\n    num_freeze_blocks = total_blocks - 3\n    \n    # FOR NO FREEZE USE\n    #num_freeze_blocks = 0\n    \n    min_lr=1e-6\n    eps=1e-6\n    betas=(0.9, 0.999)\n    max_len=512\n    weight_decay=0.01\n    gradient_accumulation_steps=1\n    max_grad_norm=1000\n    target_cols=['target']\n    seed=42\n    n_fold=5\n    trn_fold=[0,1,2,3,4]\n    train=True\n    pca_dim = 64\n    \nif CFG.debug:\n    CFG.epochs = 2\n    CFG.trn_fold = [0]","metadata":{"papermill":{"duration":0.01687,"end_time":"2022-08-31T22:31:20.284537","exception":false,"start_time":"2022-08-31T22:31:20.267667","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-10-28T20:12:59.952599Z","iopub.execute_input":"2022-10-28T20:12:59.953252Z","iopub.status.idle":"2022-10-28T20:12:59.969079Z","shell.execute_reply.started":"2022-10-28T20:12:59.953216Z","shell.execute_reply":"2022-10-28T20:12:59.968061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# wandb\n# ====================================================\nif CFG.wandb:\n    \n    import wandb\n\n    try:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n        wandb.login(key=secret_value_0)\n        anony = None\n    except:\n        anony = \"must\"\n        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n\n\n    def class2dict(f):\n        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n\n    run = wandb.init(project='FB3-Public', \n                     name=CFG.model,\n                     config=class2dict(CFG),\n                     group=CFG.model,\n                     job_type=\"train\",\n                     anonymous=anony)","metadata":{"papermill":{"duration":9.105575,"end_time":"2022-08-31T22:31:29.39563","exception":false,"start_time":"2022-08-31T22:31:20.290055","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-10-28T20:12:59.970997Z","iopub.execute_input":"2022-10-28T20:12:59.97185Z","iopub.status.idle":"2022-10-28T20:12:59.982969Z","shell.execute_reply.started":"2022-10-28T20:12:59.971815Z","shell.execute_reply":"2022-10-28T20:12:59.981874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Library","metadata":{"papermill":{"duration":0.009322,"end_time":"2022-08-31T22:31:29.415506","exception":false,"start_time":"2022-08-31T22:31:29.406184","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\n#os.system('pip install iterative-stratification==0.1.7')\n#from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\n#os.system('pip uninstall -y transformers')\n#os.system('pip uninstall -y tokenizers')\n#os.system('python -m pip install --no-index --find-links=../input/fb3-pip-wheels transformers')\n#os.system('python -m pip install --no-index --find-links=../input/fb3-pip-wheels tokenizers')\nos.system('pip install transformers --upgrade')\n#os.system('pip install tokenizers --upgrade')\n\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\nfrom transformers import get_constant_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"papermill":{"duration":58.659308,"end_time":"2022-08-31T22:32:28.084435","exception":false,"start_time":"2022-08-31T22:31:29.425127","status":"completed"},"tags":[],"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-10-28T20:12:59.986594Z","iopub.execute_input":"2022-10-28T20:12:59.987292Z","iopub.status.idle":"2022-10-28T20:13:26.383587Z","shell.execute_reply.started":"2022-10-28T20:12:59.987255Z","shell.execute_reply":"2022-10-28T20:13:26.382565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{"papermill":{"duration":0.015189,"end_time":"2022-08-31T22:32:28.113643","exception":false,"start_time":"2022-08-31T22:32:28.098454","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\ndef MCRMSE(y_trues, y_preds):\n    scores = []\n    idxes = y_trues.shape[1]\n    for i in range(idxes):\n        y_true = y_trues[:,i]\n        y_pred = y_preds[:,i]\n        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n        scores.append(score)\n    mcrmse_score = np.mean(scores)\n    return mcrmse_score, scores\n\n\ndef get_score(y_trues, y_preds):\n    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n    return mcrmse_score, scores\n\n\ndef get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"papermill":{"duration":0.039148,"end_time":"2022-08-31T22:32:28.165976","exception":false,"start_time":"2022-08-31T22:32:28.126828","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-10-28T20:13:26.388222Z","iopub.execute_input":"2022-10-28T20:13:26.390878Z","iopub.status.idle":"2022-10-28T20:13:26.409385Z","shell.execute_reply.started":"2022-10-28T20:13:26.390837Z","shell.execute_reply":"2022-10-28T20:13:26.408338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading","metadata":{"papermill":{"duration":0.010764,"end_time":"2022-08-31T22:32:28.191852","exception":false,"start_time":"2022-08-31T22:32:28.181088","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train = pd.read_csv('../input/nesp-jin-external-data/all_train_data_v17.csv')\ntrain = train.loc[train.source.str.contains('jin')]\nprint('Train has shape:', train.shape )\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:13:26.414527Z","iopub.execute_input":"2022-10-28T20:13:26.416943Z","iopub.status.idle":"2022-10-28T20:13:26.557998Z","shell.execute_reply.started":"2022-10-28T20:13:26.416896Z","shell.execute_reply":"2022-10-28T20:13:26.556939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_spaces(x):\n    return \" \".join(list(x))\ntrain.sequence = train.sequence.map(add_spaces)\ntrain.mutant_seq = train.mutant_seq.map(add_spaces)\nprint('Train has shape',train.shape)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:13:26.562795Z","iopub.execute_input":"2022-10-28T20:13:26.564774Z","iopub.status.idle":"2022-10-28T20:13:26.663763Z","shell.execute_reply.started":"2022-10-28T20:13:26.564734Z","shell.execute_reply":"2022-10-28T20:13:26.662744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"REMOVE_CT = 20\ntrain['n'] = train.groupby('PDB').PDB.transform('count')\ntrain = train.loc[train.n>REMOVE_CT]\nprint(f'After removing mutation groups with less than {REMOVE_CT} mutations, our data has shape:')\nprint( train.shape )","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:13:26.668467Z","iopub.execute_input":"2022-10-28T20:13:26.670867Z","iopub.status.idle":"2022-10-28T20:13:26.697831Z","shell.execute_reply.started":"2022-10-28T20:13:26.670805Z","shell.execute_reply":"2022-10-28T20:13:26.696989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RANK NORMALIZE EACH GROUP OF MUTATION PROTEINS\nfrom scipy.stats import rankdata\ntrain['target'] = 0.5\nfor p in train.PDB.unique():\n    target = 'dTm'\n    tmp = train.loc[train.PDB==p,'dTm']\n    if tmp.isna().sum()>len(tmp)/2: target = 'ddG'\n    train.loc[train.PDB==p,'target'] =\\\n        rankdata( train.loc[train.PDB==p,target] )/len( train.loc[train.PDB==p,target] )\ntrain = train.reset_index(drop=True)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-10-28T20:13:26.701674Z","iopub.execute_input":"2022-10-28T20:13:26.703802Z","iopub.status.idle":"2022-10-28T20:13:26.979406Z","shell.execute_reply.started":"2022-10-28T20:13:26.703758Z","shell.execute_reply":"2022-10-28T20:13:26.978403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Our train data has',train.PDB.nunique(),'unique mutation groups')","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:13:26.984504Z","iopub.execute_input":"2022-10-28T20:13:26.98684Z","iopub.status.idle":"2022-10-28T20:13:26.99757Z","shell.execute_reply.started":"2022-10-28T20:13:26.9868Z","shell.execute_reply":"2022-10-28T20:13:26.996542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV split","metadata":{"papermill":{"duration":0.009487,"end_time":"2022-08-31T22:32:28.527661","exception":false,"start_time":"2022-08-31T22:32:28.518174","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.model_selection import GroupKFold","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:13:27.002911Z","iopub.execute_input":"2022-10-28T20:13:27.00544Z","iopub.status.idle":"2022-10-28T20:13:27.011894Z","shell.execute_reply.started":"2022-10-28T20:13:27.005399Z","shell.execute_reply":"2022-10-28T20:13:27.010767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CV split\n# ====================================================\nFold = GroupKFold(n_splits=CFG.n_fold) \nfor n, (train_index, val_index) in enumerate(Fold.split(train, train[CFG.target_cols], train.PDB)):\n    train.loc[val_index, 'fold'] = int(n)\ntrain['fold'] = train['fold'].astype(int)\ndisplay(train.groupby('fold').size())","metadata":{"papermill":{"duration":0.164445,"end_time":"2022-08-31T22:32:28.706697","exception":false,"start_time":"2022-08-31T22:32:28.542252","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-10-28T20:13:27.015105Z","iopub.execute_input":"2022-10-28T20:13:27.016655Z","iopub.status.idle":"2022-10-28T20:13:27.045573Z","shell.execute_reply.started":"2022-10-28T20:13:27.016618Z","shell.execute_reply":"2022-10-28T20:13:27.044692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.debug:\n    display(train.groupby('fold').size())\n    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n    display(train.groupby('fold').size())","metadata":{"papermill":{"duration":0.016964,"end_time":"2022-08-31T22:32:28.731888","exception":false,"start_time":"2022-08-31T22:32:28.714924","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-10-28T20:13:27.053217Z","iopub.execute_input":"2022-10-28T20:13:27.055394Z","iopub.status.idle":"2022-10-28T20:13:27.062891Z","shell.execute_reply.started":"2022-10-28T20:13:27.055358Z","shell.execute_reply":"2022-10-28T20:13:27.061789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizer","metadata":{"papermill":{"duration":0.007793,"end_time":"2022-08-31T22:32:28.747828","exception":false,"start_time":"2022-08-31T22:32:28.740035","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\ntokenizer = AutoTokenizer.from_pretrained(CFG.model)\ntokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\nCFG.tokenizer = tokenizer","metadata":{"papermill":{"duration":6.683936,"end_time":"2022-08-31T22:32:35.439931","exception":false,"start_time":"2022-08-31T22:32:28.755995","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-10-28T20:13:27.0673Z","iopub.execute_input":"2022-10-28T20:13:27.070005Z","iopub.status.idle":"2022-10-28T20:13:28.452342Z","shell.execute_reply.started":"2022-10-28T20:13:27.069965Z","shell.execute_reply":"2022-10-28T20:13:28.451323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:13:28.453823Z","iopub.execute_input":"2022-10-28T20:13:28.454956Z","iopub.status.idle":"2022-10-28T20:13:28.46205Z","shell.execute_reply.started":"2022-10-28T20:13:28.454916Z","shell.execute_reply":"2022-10-28T20:13:28.460895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"papermill":{"duration":0.008087,"end_time":"2022-08-31T22:32:35.456694","exception":false,"start_time":"2022-08-31T22:32:35.448607","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\ndef prepare_input(cfg, text):\n    inputs = cfg.tokenizer.encode_plus(\n        text, \n        return_tensors=None, \n        add_special_tokens=True, \n        max_length=cfg.max_len,\n        pad_to_max_length=True,\n        truncation=True\n    )\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TrainDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts1 = df['sequence'].values\n        self.texts2 = df['mutant_seq'].values\n        self.labels = df[cfg.target_cols].values\n        self.position = df['position'].values\n\n    def __len__(self):\n        return len(self.texts1)\n\n    def __getitem__(self, item):\n        inputs1 = prepare_input(self.cfg, self.texts1[item])\n        inputs2 = prepare_input(self.cfg, self.texts2[item])\n        position = np.zeros(self.cfg.max_len)\n        position[self.position[item]] = 1\n        position = torch.tensor(position, dtype=torch.int)\n        label = torch.tensor(self.labels[item], dtype=torch.float)\n        return inputs1, inputs2, position, label\n    \n\ndef collate(inputs):\n    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n    for k, v in inputs.items():\n        inputs[k] = inputs[k][:,:mask_len]\n    return inputs","metadata":{"papermill":{"duration":0.022792,"end_time":"2022-08-31T22:32:41.717965","exception":false,"start_time":"2022-08-31T22:32:41.695173","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-10-28T20:13:28.463477Z","iopub.execute_input":"2022-10-28T20:13:28.464056Z","iopub.status.idle":"2022-10-28T20:13:28.477542Z","shell.execute_reply.started":"2022-10-28T20:13:28.464019Z","shell.execute_reply":"2022-10-28T20:13:28.476555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA Dataloader\nBelow displays the output of our data loader using a fake data example. Our data loader provides us with \"two sentences\" (i.e. both the wild type sequence and mutation sequence) and it provides us with the location of the mutation. Our model will use all this information. Note in the output that the first token id is `<cls>` and the last token id is `<eos>` and the tokens inbetween are the amino acids.","metadata":{}},{"cell_type":"code","source":"fake = pd.DataFrame(columns=['sequence','mutant_seq','position','target'])\nfake['sequence'] = ['V P V N P E','V P V N P E']\nfake['mutant_seq'] = ['V P A N P E','V P V N P C']\nfake['position'] = [3,6]\nfake['target'] = [0.2,0.8]\nfake.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:13:28.479048Z","iopub.execute_input":"2022-10-28T20:13:28.479705Z","iopub.status.idle":"2022-10-28T20:13:28.505635Z","shell.execute_reply.started":"2022-10-28T20:13:28.479668Z","shell.execute_reply":"2022-10-28T20:13:28.504178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG_fake:\n    max_len = 8\n    target_cols = ['target']\n    tokenizer = CFG.tokenizer\n    \ntrain_dataset = TrainDataset(CFG_fake, fake)\ntrain_loader = DataLoader(train_dataset,\n                          batch_size=2,\n                          shuffle=False)\nfor inputs1,inputs2,position,label in train_loader:\n    break\n    \nprint('Inputs1 =')\nprint(inputs1,'\\n')\nprint('Inputs2 =')\nprint(inputs2,'\\n')\nprint('Position =')\nprint(position,'\\n')\nprint('Label =')\nprint(label)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:13:28.507723Z","iopub.execute_input":"2022-10-28T20:13:28.508086Z","iopub.status.idle":"2022-10-28T20:13:28.529257Z","shell.execute_reply.started":"2022-10-28T20:13:28.50805Z","shell.execute_reply":"2022-10-28T20:13:28.52807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model\nThe model architecture takes both wild type sequence and mutation sequence and location of mutation as input. Then it subtracts their embeddings and concatenates that with their individual embeddings. It does this with both single mutation token position and mean pooling of entire sequence. Finally a dense layer makes the regression prediction. See the model architecture below.","metadata":{"papermill":{"duration":0.008337,"end_time":"2022-08-31T22:32:41.73492","exception":false,"start_time":"2022-08-31T22:32:41.726583","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Model\n# ====================================================\nclass MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n    \n\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n            self.config.hidden_dropout = 0.\n            self.config.hidden_dropout_prob = 0.\n            self.config.attention_dropout = 0.\n            self.config.attention_probs_dropout_prob = 0.\n            LOGGER.info(self.config)\n        else:\n            self.config = torch.load(config_path)\n            #self.config = AutoConfig.from_pretrained(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n            \n        if self.cfg.gradient_checkpointing:\n            self.model.gradient_checkpointing_enable()\n        self.pool = MeanPooling()\n        self.fc1 = nn.Linear(self.config.hidden_size, self.cfg.pca_dim)\n        self.fc2 = nn.Linear(self.cfg.pca_dim*6, 1)\n        self._init_weights(self.fc1)\n        self._init_weights(self.fc2)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs, position):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        feature = self.pool(last_hidden_states, position)\n        return feature\n\n    def forward(self, inputs1, inputs2, position):\n        feature1 = self.fc1(self.feature(inputs1, position))\n        feature2 = self.fc1(self.feature(inputs2, position))\n        \n        feature3 = self.fc1(self.feature(inputs1, inputs1['attention_mask']))\n        feature4 = self.fc1(self.feature(inputs2, inputs2['attention_mask']))        \n        \n        feature = torch.cat((feature1, feature2, feature2 - feature1,\n                             feature3, feature4, feature4 - feature3),axis=-1)\n\n        output = self.fc2(feature)\n        return output","metadata":{"papermill":{"duration":0.031877,"end_time":"2022-08-31T22:32:41.776126","exception":false,"start_time":"2022-08-31T22:32:41.744249","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-10-28T20:13:28.530992Z","iopub.execute_input":"2022-10-28T20:13:28.531392Z","iopub.status.idle":"2022-10-28T20:13:28.550264Z","shell.execute_reply.started":"2022-10-28T20:13:28.531354Z","shell.execute_reply":"2022-10-28T20:13:28.548766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss","metadata":{"papermill":{"duration":0.008836,"end_time":"2022-08-31T22:32:41.801081","exception":false,"start_time":"2022-08-31T22:32:41.792245","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Loss\n# ====================================================\nclass RMSELoss(nn.Module):\n    def __init__(self, reduction='mean', eps=1e-9):\n        super().__init__()\n        self.mse = nn.MSELoss(reduction='none')\n        self.reduction = reduction\n        self.eps = eps\n\n    def forward(self, y_pred, y_true):\n        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n        if self.reduction == 'none':\n            loss = loss\n        elif self.reduction == 'sum':\n            loss = loss.sum()\n        elif self.reduction == 'mean':\n            loss = loss.mean()\n        return loss","metadata":{"papermill":{"duration":0.023124,"end_time":"2022-08-31T22:32:41.832806","exception":false,"start_time":"2022-08-31T22:32:41.809682","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-10-28T20:13:28.552409Z","iopub.execute_input":"2022-10-28T20:13:28.552977Z","iopub.status.idle":"2022-10-28T20:13:28.565615Z","shell.execute_reply.started":"2022-10-28T20:13:28.552925Z","shell.execute_reply":"2022-10-28T20:13:28.56455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helpler functions","metadata":{"papermill":{"duration":0.008528,"end_time":"2022-08-31T22:32:41.852306","exception":false,"start_time":"2022-08-31T22:32:41.843778","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Helper functions\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    model.train()\n    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n    losses = AverageMeter()\n    start = end = time.time()\n    global_step = 0\n    for step, (inputs1, inputs2, position, labels) in enumerate(train_loader):\n        #inputs1 = collate(inputs1)\n        for k, v in inputs1.items():\n            inputs1[k] = v.to(device)\n        #inputs2 = collate(inputs2)\n        for k, v in inputs2.items():\n            inputs2[k] = v.to(device)\n        position = position.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        with torch.cuda.amp.autocast(enabled=CFG.apex):\n            y_preds = model(inputs1,inputs2,position)\n            loss = criterion(y_preds, labels)\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        losses.update(loss.item(), batch_size)\n        scaler.scale(loss).backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            global_step += 1\n            if CFG.batch_scheduler:\n                scheduler.step()\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n            print('Epoch: [{0}][{1}/{2}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad: {grad_norm:.4f}  '\n                  'LR: {lr:.8f}  '\n                  .format(epoch+1, step, len(train_loader), \n                          remain=timeSince(start, float(step+1)/len(train_loader)),\n                          loss=losses,\n                          grad_norm=grad_norm,\n                          lr=scheduler.get_lr()[0]))\n        if CFG.wandb:\n            wandb.log({f\"[fold{fold}] loss\": losses.val,\n                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n    return losses.avg\n\n\ndef valid_fn(valid_loader, model, criterion, device):\n    losses = AverageMeter()\n    model.eval()\n    preds = []\n    start = end = time.time()\n    for step, (inputs1, inputs2, position, labels) in enumerate(valid_loader):\n        #inputs = collate(inputs)\n        for k, v in inputs1.items():\n            inputs1[k] = v.to(device)\n        for k, v in inputs2.items():\n            inputs2[k] = v.to(device)\n        position = position.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        with torch.no_grad():\n            y_preds = model(inputs1,inputs2,position)\n            loss = criterion(y_preds, labels)\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n        losses.update(loss.item(), batch_size)\n        preds.append(y_preds.to('cpu').numpy())\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n            print('EVAL: [{0}/{1}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(step, len(valid_loader),\n                          loss=losses,\n                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n    predictions = np.concatenate(preds)\n    return losses.avg, predictions","metadata":{"papermill":{"duration":0.034604,"end_time":"2022-08-31T22:32:41.895844","exception":false,"start_time":"2022-08-31T22:32:41.86124","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-10-28T20:13:28.567232Z","iopub.execute_input":"2022-10-28T20:13:28.567855Z","iopub.status.idle":"2022-10-28T20:13:28.602115Z","shell.execute_reply.started":"2022-10-28T20:13:28.567809Z","shell.execute_reply":"2022-10-28T20:13:28.600987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train loop","metadata":{"papermill":{"duration":0.008782,"end_time":"2022-08-31T22:32:41.916203","exception":false,"start_time":"2022-08-31T22:32:41.907421","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# train loop\n# ====================================================\ndef train_loop(folds, fold):\n    \n    LOGGER.info(f\"========== fold: {fold} training ==========\")\n\n    # ====================================================\n    # loader\n    # ====================================================\n    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n    valid_labels = valid_folds[CFG.target_cols].values\n    print('### train shape:',train_folds.shape)\n    \n    train_dataset = TrainDataset(CFG, train_folds)\n    valid_dataset = TrainDataset(CFG, valid_folds)\n\n    train_loader = DataLoader(train_dataset,\n                              batch_size=CFG.batch_size,\n                              shuffle=True,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset,\n                              batch_size=CFG.batch_size * 2,\n                              shuffle=False,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n\n    # ====================================================\n    # model & optimizer\n    # ====================================================\n    model = CustomModel(CFG, config_path=None, pretrained=True)\n    torch.save(model.config, OUTPUT_DIR+'config.pth')\n    \n    # FREEZE LAYERS\n    if CFG.num_freeze_blocks>0:\n        print(f'### Freezing first {CFG.num_freeze_blocks} blocks.',\n              f'Leaving {CFG.total_blocks-CFG.num_freeze_blocks} blocks unfrozen')\n        for name, param in list(model.named_parameters())\\\n            [:CFG.initial_layers+CFG.layers_per_block*CFG.num_freeze_blocks]:     \n                param.requires_grad = False\n    model.to(device)\n    \n    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n        param_optimizer = list(model.named_parameters())\n        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n        optimizer_parameters = [\n            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n             'lr': encoder_lr, 'weight_decay': weight_decay},\n            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n             'lr': encoder_lr, 'weight_decay': 0.0},\n            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n             'lr': decoder_lr, 'weight_decay': 0.0}\n        ]\n        return optimizer_parameters\n\n    optimizer_parameters = get_optimizer_params(model,\n                                                encoder_lr=CFG.encoder_lr, \n                                                decoder_lr=CFG.decoder_lr,\n                                                weight_decay=CFG.weight_decay)\n    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n    \n    # ====================================================\n    # scheduler\n    # ====================================================\n    def get_scheduler(cfg, optimizer, num_train_steps):\n        if cfg.scheduler == 'linear':\n            scheduler = get_linear_schedule_with_warmup(\n                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n            )\n        elif cfg.scheduler == 'constant':\n            scheduler = get_constant_schedule_with_warmup(\n                optimizer, num_warmup_steps=cfg.num_warmup_steps\n            )\n        elif cfg.scheduler == 'cosine':\n            scheduler = get_cosine_schedule_with_warmup(\n                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n            )\n        return scheduler\n    \n    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n\n    # ====================================================\n    # loop\n    # ====================================================\n    criterion = RMSELoss(reduction=\"mean\") #nn.SmoothL1Loss(reduction='mean')\n    \n    best_score = np.inf\n\n    for epoch in range(CFG.epochs):\n\n        start_time = time.time()\n\n        # train\n        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n\n        # eval\n        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n        \n        # scoring\n        score, scores = get_score(valid_labels, predictions)\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n        if CFG.wandb:\n            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n                       f\"[fold{fold}] score\": score})\n        \n        if best_score > score:\n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save({'model': model.state_dict(),\n                        'predictions': predictions},\n                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n\n    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n                             map_location=torch.device('cpu'))['predictions']\n    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    return valid_folds","metadata":{"papermill":{"duration":0.037102,"end_time":"2022-08-31T22:32:41.962148","exception":false,"start_time":"2022-08-31T22:32:41.925046","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-10-28T20:13:28.603952Z","iopub.execute_input":"2022-10-28T20:13:28.604789Z","iopub.status.idle":"2022-10-28T20:13:28.639886Z","shell.execute_reply.started":"2022-10-28T20:13:28.604746Z","shell.execute_reply":"2022-10-28T20:13:28.638706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    \n    def get_result(oof_df):\n        labels = oof_df[CFG.target_cols].values\n        preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n        score, scores = get_score(labels, preds)\n        LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n    \n    if CFG.train:\n        oof_df = pd.DataFrame()\n        for fold in range(CFG.n_fold):\n            if fold in CFG.trn_fold:\n                _oof_df = train_loop(train, fold)\n                oof_df = pd.concat([oof_df, _oof_df])\n                LOGGER.info(f\"========== fold: {fold} result ==========\")\n                get_result(_oof_df)\n        oof_df = oof_df.reset_index(drop=True)\n        LOGGER.info(f\"========== CV ==========\")\n        get_result(oof_df)\n        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n        \n    if CFG.wandb:\n        wandb.finish()","metadata":{"papermill":{"duration":11940.406964,"end_time":"2022-09-01T01:51:42.380833","exception":false,"start_time":"2022-08-31T22:32:41.973869","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-10-28T20:13:28.641645Z","iopub.execute_input":"2022-10-28T20:13:28.642276Z","iopub.status.idle":"2022-10-28T20:48:14.067738Z","shell.execute_reply.started":"2022-10-28T20:13:28.642233Z","shell.execute_reply":"2022-10-28T20:48:14.065848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compute OOF Score","metadata":{}},{"cell_type":"code","source":"oof_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:48:14.068797Z","iopub.status.idle":"2022-10-28T20:48:14.069288Z","shell.execute_reply.started":"2022-10-28T20:48:14.069023Z","shell.execute_reply":"2022-10-28T20:48:14.06905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Here are CV scores for each mutation group in OOF:')\nfrom scipy.stats import spearmanr\nrs = []\nfor p in oof_df.PDB.unique():\n    tmp = oof_df.loc[oof_df.PDB==p]\n    \n    target = 'dTm'\n    if tmp.dTm.isna().sum()>len(tmp)/2: target = 'ddG'\n    \n    r = np.abs( spearmanr( tmp.target, tmp.pred_target ).correlation )\n    print(p,'ct=',len(tmp),'r=',r,'type=',target)\n    rs.append(r)\nprint('==> CV',np.mean(rs))","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:48:14.072593Z","iopub.status.idle":"2022-10-28T20:48:14.073383Z","shell.execute_reply.started":"2022-10-28T20:48:14.073127Z","shell.execute_reply":"2022-10-28T20:48:14.073151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Infer Test Data","metadata":{}},{"cell_type":"code","source":"CFG.path = OUTPUT_DIR\nCFG.config_path = CFG.path+'config.pth'","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:48:14.074804Z","iopub.status.idle":"2022-10-28T20:48:14.075576Z","shell.execute_reply.started":"2022-10-28T20:48:14.0753Z","shell.execute_reply":"2022-10-28T20:48:14.075324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts1 = df['sequence'].values\n        self.texts2 = df['mutant_seq'].values\n        self.position = df['position'].values\n\n    def __len__(self):\n        return len(self.texts1)\n\n    def __getitem__(self, item):\n        inputs1 = prepare_input(self.cfg, self.texts1[item])\n        inputs2 = prepare_input(self.cfg, self.texts2[item])\n        position = np.zeros(self.cfg.max_len)\n        position[self.position[item]] = 1\n        position = torch.tensor(position, dtype=torch.int)\n        return inputs1, inputs2, position","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:48:14.076944Z","iopub.status.idle":"2022-10-28T20:48:14.077823Z","shell.execute_reply.started":"2022-10-28T20:48:14.077474Z","shell.execute_reply":"2022-10-28T20:48:14.077533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for (inputs1,inputs2, position) in tk0:\n        for k, v in inputs1.items():\n            inputs1[k] = v.to(device)\n        for k, v in inputs2.items():\n            inputs2[k] = v.to(device)\n        position = position.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs1,inputs2,position)\n        preds.append(y_preds.to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:48:14.079418Z","iopub.status.idle":"2022-10-28T20:48:14.080257Z","shell.execute_reply.started":"2022-10-28T20:48:14.079965Z","shell.execute_reply":"2022-10-28T20:48:14.079991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LOAD TEST WILDTYPE\nbase = 'VPVNPEPDATSVENVALKTGSGDSQSDPIKADLEVKGQSALPFDVDCWAILCKGAPNVLQRVNEKTKNSNRDRSGANKGPFKDPQKWGIKALPPKNPSWSAQDFKSPEEYAFASSLQGGTNAILAPVNLASQNSQGGVLNGFYSANKVAQFDPSKPQQTKGTWFQITKFTGAAGPYCKALGSNDKSVCDKNKNIAGDWGFDPAKWAYQYDEKNNKFNYVGK'\nlen(base)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:48:14.081752Z","iopub.status.idle":"2022-10-28T20:48:14.082899Z","shell.execute_reply.started":"2022-10-28T20:48:14.082274Z","shell.execute_reply":"2022-10-28T20:48:14.082299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_mutation(row):\n    for i,(a,b) in enumerate(zip(row.protein_sequence,base)):\n        if a!=b: break\n    row['wildtype'] = base[i]\n    row['mutation'] = row.protein_sequence[i]\n    row['position'] = i+1\n    return row","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:48:14.084342Z","iopub.status.idle":"2022-10-28T20:48:14.085145Z","shell.execute_reply.started":"2022-10-28T20:48:14.084876Z","shell.execute_reply":"2022-10-28T20:48:14.084901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/novozymes-enzyme-stability-prediction/sample_submission.csv')\ntest = pd.read_csv('../input/novozymes-enzyme-stability-prediction/test.csv')\ntest = test.apply(get_test_mutation,axis=1)\ndeletions = test.loc[test.protein_sequence.str.len()==220,'seq_id'].values\ntest['sequence'] = base\ntest.sequence = test.sequence.map(add_spaces)\ntest = test.rename({'protein_sequence':'mutant_seq'},axis=1)\ntest.mutant_seq = test.mutant_seq.map(add_spaces)\nprint('Test data shape:', test.shape )\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:48:14.086756Z","iopub.status.idle":"2022-10-28T20:48:14.087557Z","shell.execute_reply.started":"2022-10-28T20:48:14.087278Z","shell.execute_reply":"2022-10-28T20:48:14.087303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         #collate_fn=DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding='longest'),\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions_ = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions_.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions = np.mean(predictions_, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:48:14.089024Z","iopub.status.idle":"2022-10-28T20:48:14.089829Z","shell.execute_reply.started":"2022-10-28T20:48:14.089553Z","shell.execute_reply":"2022-10-28T20:48:14.089579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['tm'] = predictions\nsubmission = submission.drop(columns=['tm']).merge(test[['seq_id','tm']], on='seq_id', how='left')\ndisplay(submission.head())\nsubmission[['seq_id','tm']].to_csv(f'submission_bert_{VER}.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:48:14.091297Z","iopub.status.idle":"2022-10-28T20:48:14.092135Z","shell.execute_reply.started":"2022-10-28T20:48:14.091869Z","shell.execute_reply":"2022-10-28T20:48:14.091894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(submission.tm, bins=100)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-28T20:48:14.093538Z","iopub.status.idle":"2022-10-28T20:48:14.094321Z","shell.execute_reply.started":"2022-10-28T20:48:14.094043Z","shell.execute_reply":"2022-10-28T20:48:14.094067Z"},"trusted":true},"execution_count":null,"outputs":[]}]}